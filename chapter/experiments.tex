\section{Dataset creation}
In order to carry out further computational analysis of the topic it is helpful to have an annotated dataset. Since no datasets exist beyond for certain aspectual parameters such as telicity \citep{friedrich-gateva-2017-classification} or stativity \citep{Friedrich2014AutomaticPO}, I had to create my own \citep{friedrich-etal-2023-kind}. The traditional route of hand-annotating including has been a standard paradigm for many years however is highly time-intensive. Crowdsourcing is a more time- and cost-effective way of creating data, however has been shown to be of variable quality \citep{li2024comparative}, especially when the task requires more expert knowledge. Furthermore there are a range of biases which can affect data quality \citep{Beck2023}. The huge success of Large Language Models in recent years has prompted some to look at utilising them for dataset annotation either on their own \citep{he2023annollm, llmsForPragAndDiscAnalysis, Gilardi_2023} or combined with human annotators \citep{goel2023llms}.

\subsection{Dataset annotation with LLMs}
I decided to annotate the 

\subsubsection*{Choice of LM model}
There has been an explosion of LMs in recent years .....

While many previous studies looking at LLM capabilities choose to look at ChatGPT models due to their notoriety in recent years and general good performance. However, as \citet{törnberg2024best} notes, these models come with several issues: it is unknown what the training data for the model is, leading to problems with transparency, and ChatGPT models have been shown to evolve over time, meaning reproducability is hindered. For these reasons, and also in order to host the model locally for better control (rather than using an API), I chose to use a different model. Meta's Llama 2 model seemed to offer a good balance between the apparent current trade-off between performance and scientific good practice, performing comparatively well in previous studies \citep{yuan2023futureTimeLlama} + OTHER EXAMPLES

\subsubsection*{Data creation}
As the only currently existing data containing UMR aspect classes, I used the example UMR dataset\footnote{ENTER LINK FOR WHERE TO FIND IT!!!!!!} provided by the creators of UMR. It contains HOW MANY sentences in 6 languages (Arapaho, Chinese, English, Kukama, Navajo and Sanapana) annotated according to the UMR schema. The texts come from WHERE 

In order to extract the verbs in the sentences I used Stanford NLP's Stanza POS tagger CITEEE, utilising the alignment given in the training data to find the corresponding node in the UMR graph and its aspect annotation. Table \ref*{umr_aspect_data} shows the class distribution of verbal events extracted from the dataset.
\begin{table}
    \centering
    \begin{tabular}{|c|c|}
        Class & Support \\ \hline
        Performance & 124 \\
        State & 55 \\
        Activity & 36 \\
        Endeavour & 17 \\
        Habitual & 2 \\ \hline
        \textbf{Total} & 234
    \end{tabular}
    \caption{Aspect classes of annotated verbal events in the UMR dataset.}
\end{table}
\label{umr_aspect_data}

Here it is clear that the \emph{habitual} class is underrepresented, corroborating the results of \citet{Dahl1985TenseAA}'s study, and hence I manually added some datapoints to improve the balance. The added sentences were either found in existing online datasets and simly labelled with a UMR aspect class by hand or they were both manually composed and then labelled.

\citet{törnberg2024best} points out that, since it is unknown exactly which training data was used to train many LMs, one should exercise caution when evaluating their performance on a test set, since the model may have seen the test data before during pre-training. In this case, while it is impossible to rule out that the UMR dataset was used for Llama 2 pretraining, it is highly unlikely that it has seen the data in this form (i.e. as a sentence, a verb from this sentence and a UMR aspect label for this verb), and since the model was pre-trained with a next-token prediction task, it is highly unlikely that it would have memorised the labels for the data it is being tested on in my experiments. Nevertheless this cannot be ruled out and must be kept in mind when analysing the results.

One interesting feature of the UMR \texttt{:aspect} parameter, is that it is used not only with verbs in the source sentence but also with nouns and adjectives:

\begin{exe}
    \ex 200 dead , 1,500 feared missing in Philippines landslide .
\end{exe}

Since Russian NLP tools are scarce, it would be difficult to perform event extraction, so, in order to keep the results comparable between both languages, I chose to just to focus on verbal events. In my analysis the \texttt{:aspect} parameter occurred with a verb in the source sentence $74.8\%$ of the time, meaning most of the data from the UMR dataset could be used.

\subsubsection*{Prompt engineering}
The model was given the following instruction for each datapoint:
\begin{quotation}
    The annotation distinguishes five base level aspectual values—State, Habitual, Activity, Endeavor, and Performance. The State value corresponds to stative events: no change occurs during the event. It also includes predicate nominals (be a doctor), predicate locations (be in the forest), and thetic (presentational) possession (have a cat). The Habitual value is annotated on events that occur regularly in the past or present. The Activity value indicates an event has not necessarily ended and may be ongoing at Document Creation Time (DCT). Endeavor is used for processes that end without reaching completion (i.e., termination), whereas Performance is used for processes that reach a completed result state. 
\end{quotation}
followed by the following question:
\begin{quotation}
    Which class does "\emph{\{verb\}}" belong to in this sentence: state, habitual, activity, endeavor, or performance?"
\end{quotation}

Due to hardware constraints, I had to use a technique to improve the efficiency of the model training process since the smallest llama model is 7 billion parameters. In this case I chose to use PEFT (Parameter efficint fine-tuning) (ADD CITATION), which leverages the insight that LM fine-tuning usually only updates parameters at the end of the model. This made it possible to fine-tune the model without resorting to the huge amount of computing power usually necessary for fine-tuning LLMs.

I experimented both with the standard \textsf{Llama-2-7b} and \textsf{Llama-2-7b-chat} \citep{touvron2023llama}, however the latter ended up having difficulties responding in a formulaic way and rather added unnecessary or unrelated information, which is to be expected since it has been fine-tuned to fare well in a dialogue environment. This made it often difficult to extract the model's predicted label to use for evaluation. 

\subsection*{Best practices for using LLMs as annotators}
\citet{törnberg2024best} formulated a set of best practices when using LLMs as text annotators, which I aim to follow.

\subsubsection*{Systematic coding procedure}
\subsubsection*{Develop a prompt codebook}
With annotation guide for human annotators
\subsubsection*{Validate the model}
\subsubsection*{Prompt engineering}
Return as JSON
\subsubsection*{Examine model stochastisity}


\subsection{Language model fine-tuning}
\subsubsection{Ablation (aspectualisation and contextualisation)}
\subsubsection{Combined Rus/Eng model}
\subsection{Probing}
\subsection{Aspect latent space}
\subsubsection{Verb of motion clustering}
\subsubsection{Prefix clustering}